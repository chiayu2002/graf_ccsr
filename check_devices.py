#!/usr/bin/env python3
"""
è¨­å‚™è¨ºæ–·è…³æœ¬
ç”¨æ–¼æª¢æŸ¥è¨“ç·´éç¨‹ä¸­æ‰€æœ‰å¼µé‡çš„è¨­å‚™ä½ç½®
"""

import torch
import sys

def check_devices():
    """æª¢æŸ¥è¨­å‚™è¨­ç½®"""
    print("=" * 60)
    print("è¨­å‚™è¨ºæ–·å ±å‘Š")
    print("=" * 60)

    # æª¢æŸ¥ CUDA å¯ç”¨æ€§
    print(f"\n1. CUDA å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   CUDA è¨­å‚™æ•¸é‡: {torch.cuda.device_count()}")
        print(f"   ç•¶å‰ CUDA è¨­å‚™: {torch.cuda.current_device()}")
        print(f"   è¨­å‚™åç¨±: {torch.cuda.get_device_name(0)}")

    # è¨­ç½®è¨­å‚™
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"\n2. ä½¿ç”¨çš„è¨­å‚™: {device}")

    # æ¨¡æ“¬è¨“ç·´å¾ªç’°ä¸­çš„å¼µé‡å‰µå»º
    print("\n3. æ¨¡æ“¬å¼µé‡æ“ä½œ:")
    try:
        # æ¨¡æ“¬å¾ DataLoader ç²å–æ•¸æ“šï¼ˆé»˜èªåœ¨ CPUï¼‰
        batch_size = 8
        label_cpu = torch.randn(batch_size, 3)
        print(f"   åŸå§‹ label è¨­å‚™: {label_cpu.device}")

        # ç§»åˆ° GPU
        label_gpu = label_cpu.to(device, non_blocking=True)
        print(f"   ç§»å‹•å¾Œ label è¨­å‚™: {label_gpu.device}")

        # æå– first_label
        first_label = label_gpu[:,0].long()
        print(f"   first_label è¨­å‚™: {first_label.device}")

        # å‰µå»º one_hot
        one_hot = torch.zeros(batch_size, 1, device=device)
        print(f"   one_hot è¨­å‚™: {one_hot.device}")

        # æ¸¬è©¦ scatter æ“ä½œ
        one_hot.scatter_(1, first_label.unsqueeze(1), 1)
        print(f"   âœ… scatter_ æ“ä½œæˆåŠŸ!")

        print("\nâœ… æ‰€æœ‰è¨­å‚™æ“ä½œæ­£å¸¸!")
        return True

    except RuntimeError as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        print("\nå¯èƒ½çš„åŸå› :")
        print("1. label æœªæ­£ç¢ºç§»åˆ° GPU")
        print("2. first_label å’Œ one_hot åœ¨ä¸åŒè¨­å‚™")
        return False

def test_dataloader_device():
    """æ¸¬è©¦ DataLoader çš„è¨­å‚™è¡Œç‚º"""
    print("\n" + "=" * 60)
    print("DataLoader è¨­å‚™æ¸¬è©¦")
    print("=" * 60)

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    # å‰µå»ºç°¡å–®çš„æ•¸æ“šé›†
    dummy_data = torch.randn(16, 3, 64, 64)
    dummy_labels = torch.randint(0, 10, (16, 3))

    dataset = torch.utils.data.TensorDataset(dummy_data, dummy_labels)
    dataloader = torch.utils.data.DataLoader(
        dataset,
        batch_size=4,
        shuffle=False,
        pin_memory=True
    )

    print(f"\nå¾ DataLoader æå–ç¬¬ä¸€å€‹ batch:")
    for x, label in dataloader:
        print(f"   x è¨­å‚™: {x.device}")
        print(f"   label è¨­å‚™: {label.device}")

        # æ¸¬è©¦ç§»å‹•åˆ° GPU
        x = x.to(device, non_blocking=True)
        label = label.to(device, non_blocking=True)

        print(f"\n   ç§»å‹•å¾Œ x è¨­å‚™: {x.device}")
        print(f"   ç§»å‹•å¾Œ label è¨­å‚™: {label.device}")

        # æ¸¬è©¦æ“ä½œ
        first_label = label[:,0].long()
        print(f"   first_label è¨­å‚™: {first_label.device}")

        one_hot = torch.zeros(label.size(0), 1, device=device)
        print(f"   one_hot è¨­å‚™: {one_hot.device}")

        try:
            one_hot.scatter_(1, first_label.unsqueeze(1), 1)
            print(f"\n   âœ… DataLoader æ¸¬è©¦æˆåŠŸ!")
        except RuntimeError as e:
            print(f"\n   âŒ DataLoader æ¸¬è©¦å¤±æ•—: {e}")

        break  # åªæ¸¬è©¦ç¬¬ä¸€å€‹ batch

def print_recommendations():
    """æ‰“å°å»ºè­°"""
    print("\n" + "=" * 60)
    print("ä¿®å¾©å»ºè­°")
    print("=" * 60)
    print("""
å¦‚æœæ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä»¥ä¸‹å¹¾é»ï¼š

1. ç¢ºä¿ä½ å·²ç¶“å¾ Git æ‹‰å–æœ€æ–°ä»£ç¢¼:
   cd /Data/home/vicky/graf250916/
   git pull origin claude/code-review-011CUKo9GJraRmNXfGkcWKxR

2. æª¢æŸ¥ train.py ç¬¬ 180-181 è¡Œæ˜¯å¦æœ‰ä»¥ä¸‹ä»£ç¢¼:
   x_real = x_real.to(device, non_blocking=True)
   label = label.to(device, non_blocking=True)

3. å¦‚æœé‚„æœ‰å•é¡Œï¼Œæ‰‹å‹•æ·»åŠ èª¿è©¦ä»£ç¢¼:
   åœ¨ train.py ç¬¬ 184 è¡Œå¾Œæ·»åŠ :

   print(f"Debug - label device: {label.device}")
   print(f"Debug - first_label device: {first_label.device}")
   print(f"Debug - one_hot device: {one_hot.device}")

4. ç¢ºä¿æ²’æœ‰æ··ç”¨ä¸åŒç‰ˆæœ¬çš„ä»£ç¢¼æ–‡ä»¶

5. æ¸…ç† Python ç·©å­˜:
   find . -type d -name "__pycache__" -exec rm -r {} +
   find . -type f -name "*.pyc" -delete
""")

if __name__ == "__main__":
    print("\nğŸ” é–‹å§‹è¨­å‚™è¨ºæ–·...\n")

    # é‹è¡Œæ¸¬è©¦
    basic_test = check_devices()
    test_dataloader_device()
    print_recommendations()

    # ç¸½çµ
    print("\n" + "=" * 60)
    if basic_test:
        print("âœ… è¨ºæ–·å®Œæˆ - è¨­å‚™é…ç½®æ­£å¸¸")
        print("\nå¦‚æœè¨“ç·´é‚„æœ‰å•é¡Œï¼Œè«‹ç¢ºä¿:")
        print("1. ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„ train.py")
        print("2. æ¸…ç† Python ç·©å­˜")
        print("3. é‡å•Ÿ Python ç’°å¢ƒ")
    else:
        print("âŒ è¨ºæ–·å®Œæˆ - ç™¼ç¾è¨­å‚™å•é¡Œ")
        print("\nè«‹æª¢æŸ¥ä¸Šé¢çš„ä¿®å¾©å»ºè­°")
    print("=" * 60 + "\n")
