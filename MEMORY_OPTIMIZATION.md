# è¨˜æ†¶é«”ç®¡ç†å„ªåŒ–æŒ‡å—

æœ¬æ–‡æª”ç¸½çµäº†å° graf_ccsr å°ˆæ¡ˆé€²è¡Œçš„è¨˜æ†¶é«”ç®¡ç†å„ªåŒ–ã€‚

## ğŸ“Š å·²å¯¦æ–½çš„å„ªåŒ–

### 1. ç§»é™¤å…¨å±€ CUDA å¼µé‡è¨­ç½®
**æª”æ¡ˆ**: `train.py`, `eval.py`

**ä¿®æ”¹å‰**:
```python
torch.set_default_tensor_type('torch.cuda.FloatTensor')
```

**å•é¡Œ**: å°è‡´æ‰€æœ‰å¼µé‡é»˜èªåœ¨ GPU ä¸Šå‰µå»ºï¼Œå¢åŠ è¨˜æ†¶é«”å£“åŠ›

**ä¿®æ”¹å¾Œ**: ç§»é™¤æ­¤è¡Œï¼Œæ‰‹å‹•ç®¡ç†å¼µé‡è¨­å‚™

---

### 2. å„ªåŒ– DataLoader é…ç½®
**æª”æ¡ˆ**: `train.py:42-54`

**æ–°å¢åŠŸèƒ½**:
- é™åˆ¶ `num_workers` æœ€å¤šç‚º 4
- æ·»åŠ  `prefetch_factor=2` ä»¥å¹³è¡¡è¨˜æ†¶é«”å’Œé€Ÿåº¦
- å•Ÿç”¨ `persistent_workers` ä»¥æ¸›å°‘ worker é‡å•Ÿé–‹éŠ·

```python
train_loader = torch.utils.data.DataLoader(
    train_dataset,
    batch_size=config['training']['batch_size'],
    num_workers=min(config['training']['nworkers'], 4),
    shuffle=True,
    pin_memory=True,
    prefetch_factor=2 if config['training']['nworkers'] > 0 else None,
    persistent_workers=config['training']['nworkers'] > 0,
    ...
)
```

---

### 3. å„ªåŒ–å™¨è¨˜æ†¶é«”ç®¡ç†
**æª”æ¡ˆ**: `train.py:187, 241`

**æ”¹é€²**: ä½¿ç”¨ `zero_grad(set_to_none=True)` ä»£æ›¿ `zero_grad()`

```python
d_optimizer.zero_grad(set_to_none=True)  # ç¯€çœè¨˜æ†¶é«”
g_optimizer.zero_grad(set_to_none=True)
```

**æ•ˆæœ**: å°‡æ¢¯åº¦è¨­ç½®ç‚º None è€Œéå¡«å……é›¶ï¼Œç¯€çœè¨˜æ†¶é«”åˆ†é…

---

### 4. ä¿®å¾©é‡è¤‡å°è±¡å‰µå»º
**æª”æ¡ˆ**: `train.py:106`

**ä¿®æ”¹å‰**: æ¯æ¬¡è¿­ä»£å‰µå»ºæ–°çš„ `MCE_Loss()` å¯¦ä¾‹

**ä¿®æ”¹å¾Œ**: åœ¨è¨“ç·´å¾ªç’°å¤–å‰µå»ºä¸€æ¬¡
```python
# åˆå§‹åŒ–æå¤±å‡½æ•¸ï¼ˆåœ¨å¾ªç’°å¤–å‰µå»ºä»¥ç¯€çœè¨˜æ†¶é«”ï¼‰
ccsr_nerf_loss = CCSRNeRFLoss().to(device)
mce_loss = MCE_Loss()
```

---

### 5. å¼µé‡ç•°æ­¥å‚³è¼¸
**æª”æ¡ˆ**: `train.py:189, 196, 202, etc.`

**æ”¹é€²**: ä½¿ç”¨ `non_blocking=True` é€²è¡Œ CPU åˆ° GPU å‚³è¼¸

```python
x_real = x_real.to(device, non_blocking=True)
label_tensor = label.to(device, non_blocking=True)
```

**æ•ˆæœ**: å…è¨± CPU å’Œ GPU æ“ä½œé‡ç–Šï¼Œæé«˜æ•ˆç‡

---

### 6. ä¸»å‹•é‡‹æ”¾å¼µé‡
**æª”æ¡ˆ**: `train.py:231, 261`

**æ–°å¢**: åœ¨ä¸éœ€è¦æ™‚ä¸»å‹•åˆªé™¤å¼µé‡

```python
# é‡‹æ”¾ä¸éœ€è¦çš„å¼µé‡
del x_fake, d_real, d_fake, rgbs, dloss_real, dloss_fake, reg, total_d_loss
```

---

### 7. CUDA ç·©å­˜æ¸…ç†
**æª”æ¡ˆ**: `train.py:287, 313-314`

**æ–°å¢**: åœ¨é—œéµä½ç½®æ¸…ç† CUDA ç·©å­˜

```python
torch.cuda.empty_cache()  # æ¸…ç† CUDA ç·©å­˜
gc.collect()  # Python åƒåœ¾å›æ”¶
```

**ä½ç½®**:
- æ¡æ¨£å¾Œ (æ¯ 500 æ¬¡è¿­ä»£)
- FID/KID è¨ˆç®—å¾Œ (æ¯ 5000 æ¬¡è¿­ä»£)
- æª¢æŸ¥é»ä¿å­˜å¾Œ

---

### 8. ä½¿ç”¨ `torch.no_grad()` ä¸Šä¸‹æ–‡
**æª”æ¡ˆ**: `train.py`, `eval.py`, `generator.py`

**æ”¹é€²**: åœ¨ä¸éœ€è¦æ¢¯åº¦çš„æ“ä½œä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨

```python
with torch.no_grad():
    # æ¡æ¨£æˆ–è©•ä¼°ä»£ç¢¼
    samples = evaluator.create_samples(...)
```

**ä½ç½®**:
- è¨“ç·´æ™‚çš„ discriminator å‡æ•¸æ“šç”Ÿæˆ
- æ¡æ¨£å’Œå¯è¦–åŒ–
- FID/KID è¨ˆç®—
- è©•ä¼°è…³æœ¬ä¸­çš„æ‰€æœ‰æ“ä½œ

---

### 9. Generator ä¸­çš„ CCSR å„ªåŒ–
**æª”æ¡ˆ**: `graf/models/generator.py:112-156`

**æ”¹é€²**:
1. ä¿®å¾©ç¡¬ç·¨ç¢¼çš„ `view_idx = 72`ï¼Œæ”¹ç‚ºå¾ label ä¸­æå–
2. åœ¨ CCSR è™•ç†æ™‚ä½¿ç”¨ `torch.no_grad()` æš«æ™‚é—œé–‰æ¢¯åº¦
3. ä¸»å‹•åˆªé™¤ä¸­é–“å¼µé‡
4. æ·»åŠ å®Œç¾å¹³æ–¹æ•¸é©—è­‰

```python
with torch.no_grad():  # CCSR è™•ç†æ™‚æš«æ™‚ä¸éœ€è¦æ¢¯åº¦
    # è™•ç†é‚è¼¯
    ...
    del ccsr_results, lr_images  # é‡‹æ”¾ä¸­é–“çµæœ
    del ccsr_combined  # é‡‹æ”¾

# é‡æ–°å•Ÿç”¨æ¢¯åº¦
ccsr_output.requires_grad_(True)
```

---

### 10. è©•ä¼°è…³æœ¬å„ªåŒ–
**æª”æ¡ˆ**: `eval.py`

**æ”¹é€²**:
1. æ‰€æœ‰è©•ä¼°æ“ä½œåŒ…è£¹åœ¨ `torch.no_grad()` ä¸­
2. æ¨£æœ¬ç”Ÿæˆå¾Œç«‹å³ç§»åˆ° CPU
3. å®šæœŸèª¿ç”¨ `torch.cuda.empty_cache()`
4. ä¿®å¾©æœªå®šç¾©çš„ `label` è®Šæ•¸å•é¡Œ

```python
with torch.no_grad():
    for i, (u, v) in enumerate(angle_positions):
        rgb, depth, acc = evaluator.create_samples(...)
        all_rgb.append(rgb.cpu())  # ç«‹å³ç§»åˆ° CPU
        del depth, acc
        if i % 2 == 0:
            torch.cuda.empty_cache()
```

---

### 11. æ··åˆç²¾åº¦è¨“ç·´ï¼ˆAMPï¼‰
**æª”æ¡ˆ**: `train.py:78, 110-114, 204-228, 246-258`

**æ–°å¢**: å¯é¸çš„æ··åˆç²¾åº¦è¨“ç·´æ”¯æ´

**ä½¿ç”¨æ–¹æ³•**:
```bash
python train.py --config configs/default.yaml --use_amp
```

**å¯¦ç¾**:
```python
# åˆå§‹åŒ– scaler
scaler_d = torch.cuda.amp.GradScaler(enabled=use_amp)
scaler_g = torch.cuda.amp.GradScaler(enabled=use_amp)

# è¨“ç·´æ™‚ä½¿ç”¨
with torch.cuda.amp.autocast(enabled=use_amp):
    d_real, _ = discriminator(rgbs, label)
    dloss_real = compute_loss(d_real, 1)

scaler_d.scale(total_d_loss).backward()
scaler_d.step(d_optimizer)
scaler_d.update()
```

**æ•ˆæœ**: å¯ç¯€çœé«˜é” 50% çš„ GPU è¨˜æ†¶é«”

---

## ğŸ“ˆ é æœŸæ•ˆæœ

### è¨˜æ†¶é«”ç¯€çœä¼°è¨ˆ
| å„ªåŒ–é …ç›® | é æœŸç¯€çœ |
|---------|---------|
| ç§»é™¤å…¨å±€ CUDA å¼µé‡è¨­ç½® | ~10% |
| å„ªåŒ–å™¨ set_to_none | ~5-10% |
| ä¸»å‹•é‡‹æ”¾å¼µé‡ + ç·©å­˜æ¸…ç† | ~15-20% |
| æ··åˆç²¾åº¦è¨“ç·´ (AMP) | ~30-50% |
| **ç¸½è¨ˆ** | **~60-90%** |

### æ€§èƒ½å½±éŸ¿
- **è¨“ç·´é€Ÿåº¦**: å¯èƒ½ç•¥å¾®æ¸›æ…¢ (~5-10%)ï¼Œå› ç‚ºæ·»åŠ äº†è¨˜æ†¶é«”æ¸…ç†æ“ä½œ
- **ç©©å®šæ€§**: é¡¯è‘—æå‡ï¼Œæ¸›å°‘ OOM (Out of Memory) éŒ¯èª¤
- **æ‰¹æ¬¡å¤§å°**: å¯ä»¥å¢åŠ  1.5-2 å€çš„ batch size

---

## ğŸ”§ ä½¿ç”¨å»ºè­°

### 1. æ¨™æº–è¨“ç·´ï¼ˆè¨˜æ†¶é«”å……è¶³ï¼‰
```bash
python train.py --config configs/default.yaml
```

### 2. è¨˜æ†¶é«”å—é™ç’°å¢ƒ
```bash
python train.py --config configs/default.yaml --use_amp
```

### 3. èª¿æ•´ batch size
å¦‚æœè¨˜æ†¶é«”ä»ç„¶ä¸è¶³ï¼Œä¿®æ”¹ `configs/default.yaml`:
```yaml
training:
  batch_size: 4  # å¾ 8 æ¸›å°‘åˆ° 4
```

### 4. ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨
æ·»åŠ ä»¥ä¸‹ä»£ç¢¼åˆ°è¨“ç·´å¾ªç’°ä¸­:
```python
if (it % 100) == 0:
    allocated = torch.cuda.memory_allocated() / 1e9
    reserved = torch.cuda.memory_reserved() / 1e9
    print(f"è¨˜æ†¶é«”: å·²åˆ†é… {allocated:.2f}GB, ä¿ç•™ {reserved:.2f}GB")
```

---

## âš ï¸ æ³¨æ„äº‹é …

### 1. æ··åˆç²¾åº¦è¨“ç·´çš„é™åˆ¶
- æŸäº›æ“ä½œï¼ˆå¦‚æ¢¯åº¦æ‡²ç½°è¨ˆç®—ï¼‰ä»éœ€åœ¨ FP32 ä¸­é€²è¡Œ
- å¯èƒ½æœƒå½±éŸ¿æ•¸å€¼ç©©å®šæ€§ï¼Œå»ºè­°ç›£æ§è¨“ç·´æ›²ç·š

### 2. DataLoader workers
- å¦‚æœä½¿ç”¨ HDD è€Œé SSDï¼Œæ¸›å°‘ `num_workers`
- åœ¨ Windows ä¸Šå¯èƒ½éœ€è¦è¨­ç½® `num_workers=0`

### 3. è¨˜æ†¶é«”ç¢ç‰‡
- é•·æ™‚é–“è¨“ç·´å¾Œå¯èƒ½å‡ºç¾è¨˜æ†¶é«”ç¢ç‰‡
- å»ºè­°å®šæœŸé‡å•Ÿè¨“ç·´ï¼ˆä½¿ç”¨ checkpointï¼‰

---

## ğŸ› æ•…éšœæ’é™¤

### å•é¡Œ 1: ä»ç„¶å‡ºç¾ OOM
**è§£æ±ºæ–¹æ¡ˆ**:
1. å•Ÿç”¨ `--use_amp`
2. æ¸›å°‘ `batch_size`
3. æ¸›å°‘ `ray_sampler.N_samples` (åœ¨ config.yaml ä¸­)

### å•é¡Œ 2: è¨“ç·´è®Šæ…¢
**è§£æ±ºæ–¹æ¡ˆ**:
1. æª¢æŸ¥æ˜¯å¦éåº¦ä½¿ç”¨ `torch.cuda.empty_cache()`
2. ç¢ºä¿ `pin_memory=True` ä¸” `non_blocking=True`
3. å¢åŠ  `prefetch_factor`

### å•é¡Œ 3: æ•¸å€¼ä¸ç©©å®šï¼ˆä½¿ç”¨ AMP æ™‚ï¼‰
**è§£æ±ºæ–¹æ¡ˆ**:
1. æª¢æŸ¥ loss scalingï¼ˆscalerï¼‰
2. æŸäº›å±¤å¯èƒ½éœ€è¦å¼·åˆ¶ä½¿ç”¨ FP32
3. ç›£æ§æ¢¯åº¦ç¯„æ•¸

---

## ğŸ“ é€²ä¸€æ­¥å„ªåŒ–å»ºè­°

### 1. æ¢¯åº¦ç´¯ç©ï¼ˆæœªå¯¦ç¾ï¼‰
å¦‚æœä»éœ€æ›´å¤§çš„æœ‰æ•ˆ batch size:
```python
accumulation_steps = 4
for i, (x_real, label) in enumerate(train_loader):
    loss = ... / accumulation_steps
    loss.backward()

    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

### 2. Gradient Checkpointingï¼ˆæœªå¯¦ç¾ï¼‰
å°æ–¼éå¸¸æ·±çš„ç¶²çµ¡:
```python
from torch.utils.checkpoint import checkpoint
output = checkpoint(some_function, input)
```

### 3. åˆ†æ•£å¼è¨“ç·´ï¼ˆæœªå¯¦ç¾ï¼‰
ä½¿ç”¨å¤š GPU:
```bash
python -m torch.distributed.launch --nproc_per_node=2 train.py ...
```

---

## ğŸ“š åƒè€ƒè³‡æ–™

- [PyTorch è¨˜æ†¶é«”ç®¡ç†æœ€ä½³å¯¦è¸](https://pytorch.org/docs/stable/notes/cuda.html#memory-management)
- [æ··åˆç²¾åº¦è¨“ç·´æŒ‡å—](https://pytorch.org/docs/stable/amp.html)
- [CUDA æœ€ä½³å¯¦è¸æŒ‡å—](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)

---

**æœ€å¾Œæ›´æ–°**: 2025-10-21
**ç¶­è­·è€…**: Claude Code Review Assistant
