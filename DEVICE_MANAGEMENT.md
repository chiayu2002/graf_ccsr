# GPU è¨­å‚™ç®¡ç†æª¢æŸ¥æ¸…å–®

æœ¬æ–‡æª”åˆ—å‡ºäº†æ‰€æœ‰å·²ä¿®å¾©çš„è¨­å‚™ä¸åŒ¹é…å•é¡Œï¼Œä»¥åŠå¦‚ä½•é¿å…æœªä¾†å‡ºç¾é¡ä¼¼éŒ¯èª¤ã€‚

## ğŸ”´ å·²ä¿®å¾©çš„è¨­å‚™éŒ¯èª¤

### éŒ¯èª¤ 1: DataLoader ä¸­çš„æ•¸æ“šæœªç§»åˆ° GPU
**ä½ç½®**: `train.py:176-183`

**éŒ¯èª¤è¨Šæ¯**:
```
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
```

**åŸå› **:
```python
# éŒ¯èª¤çš„ä»£ç¢¼
for x_real, label in tqdm(train_loader):
    first_label = label[:,0].long()  # label åœ¨ CPU ä¸Š
    one_hot = torch.zeros(batch_size, 1, device=device)  # one_hot åœ¨ GPU ä¸Š
    one_hot.scatter_(1, first_label.unsqueeze(1), 1)  # âŒ è¨­å‚™ä¸åŒ¹é…ï¼
```

**ä¿®å¾©**:
```python
# æ­£ç¢ºçš„ä»£ç¢¼
for x_real, label in tqdm(train_loader):
    # ç«‹å³å°‡æ•¸æ“šç§»åˆ° GPU
    x_real = x_real.to(device, non_blocking=True)
    label = label.to(device, non_blocking=True)

    first_label = label[:,0].long()  # âœ… ç¾åœ¨åœ¨ GPU ä¸Š
    one_hot = torch.zeros(batch_size, 1, device=device)
    one_hot.scatter_(1, first_label.unsqueeze(1), 1)  # âœ… éƒ½åœ¨ GPU ä¸Š
```

**å½±éŸ¿æ–‡ä»¶**: `train.py:180-181`

---

### éŒ¯èª¤ 2: é‡è¤‡çš„è¨­å‚™è½‰æ›
**ä½ç½®**: `train.py:205, 214, 217, 246, 247`

**å•é¡Œ**:
```python
# æ•ˆç‡ä½ä¸‹ä¸”å®¹æ˜“å‡ºéŒ¯
label.to(device, non_blocking=True)  # è½‰æ›å¤šæ¬¡
label.to(device, non_blocking=True)  # é‡è¤‡è½‰æ›
label.to(device, non_blocking=True)  # åˆä¸€æ¬¡è½‰æ›
```

**ä¿®å¾©**:
```python
# åœ¨å¾ªç’°é–‹å§‹æ™‚è½‰æ›ä¸€æ¬¡
label = label.to(device, non_blocking=True)
# ä¹‹å¾Œç›´æ¥ä½¿ç”¨ label
```

**å½±éŸ¿**: æ¸›å°‘ä¸å¿…è¦çš„è¨­å‚™è½‰æ›ï¼Œæé«˜æ•ˆç‡

---

### éŒ¯èª¤ 3: æ¡æ¨£æ™‚å‰µå»ºçš„å¼µé‡æœªæŒ‡å®šè¨­å‚™
**ä½ç½®**: `train.py:291`

**éŒ¯èª¤ä»£ç¢¼**:
```python
label_test = torch.tensor([[0] if i < 4 else [0] for i in range(batch_size)])
# âŒ é»˜èªåœ¨ CPU ä¸Š
```

**ä¿®å¾©**:
```python
label_test = torch.tensor([[0] if i < 4 else [0] for i in range(batch_size)], device=device)
# âœ… æ˜ç¢ºæŒ‡å®šè¨­å‚™
```

---

### éŒ¯èª¤ 4: eval.py ä¸­çš„ create_labels å‡½æ•¸
**ä½ç½®**: `eval.py:122`

**éŒ¯èª¤ä»£ç¢¼**:
```python
def create_labels(num_samples, label_value):
    return torch.full((num_samples, 1), label_value)  # âŒ åœ¨ CPU ä¸Š
```

**ä¿®å¾©**:
```python
def create_labels(num_samples, label_value):
    return torch.full((num_samples, 1), label_value, device=device)  # âœ… åœ¨ GPU ä¸Š
```

---

## âœ… è¨­å‚™ç®¡ç†æœ€ä½³å¯¦è¸

### 1. åœ¨è¨“ç·´å¾ªç’°é–‹å§‹æ™‚ç«‹å³ç§»å‹•æ•¸æ“š

```python
# âœ… å¥½çš„åšæ³•
for x, label in dataloader:
    x = x.to(device, non_blocking=True)
    label = label.to(device, non_blocking=True)
    # å¾ŒçºŒæ‰€æœ‰æ“ä½œä½¿ç”¨å·²ç§»å‹•çš„å¼µé‡

# âŒ ä¸å¥½çš„åšæ³•
for x, label in dataloader:
    output = model(x.to(device))  # æ¯æ¬¡éƒ½è½‰æ›
    loss = criterion(output, label.to(device))  # é‡è¤‡è½‰æ›
```

### 2. å‰µå»ºå¼µé‡æ™‚æ˜ç¢ºæŒ‡å®šè¨­å‚™

```python
# âœ… å¥½çš„åšæ³•
zeros = torch.zeros(size, device=device)
ones = torch.ones(size, device=device)
tensor = torch.tensor(data, device=device)
full = torch.full(size, value, device=device)

# âŒ ä¸å¥½çš„åšæ³•
zeros = torch.zeros(size).to(device)  # å…ˆåœ¨ CPU å‰µå»ºå†ç§»å‹•
```

### 3. ä½¿ç”¨ non_blocking=True åŠ é€Ÿç•°æ­¥å‚³è¼¸

```python
# âœ… ç•°æ­¥å‚³è¼¸ï¼ˆç•¶ pin_memory=True æ™‚æ›´å¿«ï¼‰
x = x.to(device, non_blocking=True)

# âŒ åŒæ­¥å‚³è¼¸ï¼ˆè¼ƒæ…¢ï¼‰
x = x.to(device)
```

### 4. åœ¨æ¨ç†æ™‚ä½¿ç”¨ torch.no_grad()

```python
# âœ… ç¯€çœè¨˜æ†¶é«”
with torch.no_grad():
    output = model(x)

# âŒ æœƒè¿½è¹¤æ¢¯åº¦ï¼Œæµªè²»è¨˜æ†¶é«”
output = model(x)
```

---

## ğŸ” å¦‚ä½•æª¢æ¸¬è¨­å‚™ä¸åŒ¹é…å•é¡Œ

### æ–¹æ³• 1: åœ¨é—œéµä½ç½®æ·»åŠ æ–·è¨€

```python
def forward(self, x, label):
    # æª¢æŸ¥è¼¸å…¥æ˜¯å¦åœ¨åŒä¸€è¨­å‚™
    assert x.device == label.device, f"Device mismatch: x on {x.device}, label on {label.device}"
    assert x.device.type == 'cuda', f"Expected CUDA device, got {x.device}"

    # ç¹¼çºŒè™•ç†
    ...
```

### æ–¹æ³• 2: æ‰“å°å¼µé‡è¨­å‚™

```python
print(f"x device: {x.device}")
print(f"label device: {label.device}")
print(f"model device: {next(model.parameters()).device}")
```

### æ–¹æ³• 3: ä½¿ç”¨èª¿è©¦å·¥å…·

```python
# å•Ÿç”¨ç•°å¸¸æª¢æ¸¬
torch.autograd.set_detect_anomaly(True)
```

---

## ğŸ“‹ æª¢æŸ¥æ¸…å–®

åœ¨æ·»åŠ æ–°ä»£ç¢¼æ™‚ï¼Œæª¢æŸ¥ä»¥ä¸‹é …ç›®ï¼š

### DataLoader
- [ ] å¾ DataLoader ç²å–çš„æ•¸æ“šæ˜¯å¦ç«‹å³ç§»åˆ° GPUï¼Ÿ
- [ ] æ˜¯å¦ä½¿ç”¨ `non_blocking=True`ï¼Ÿ
- [ ] æ˜¯å¦åœ¨ DataLoader ä¸­è¨­ç½® `pin_memory=True`ï¼Ÿ

### å¼µé‡å‰µå»º
- [ ] æ‰€æœ‰ `torch.tensor()` æ˜¯å¦æŒ‡å®š `device=device`ï¼Ÿ
- [ ] æ‰€æœ‰ `torch.zeros()`, `torch.ones()` æ˜¯å¦æŒ‡å®š `device=device`ï¼Ÿ
- [ ] æ‰€æœ‰ `torch.full()`, `torch.empty()` æ˜¯å¦æŒ‡å®š `device=device`ï¼Ÿ

### æ¨¡å‹æ“ä½œ
- [ ] æ¨¡å‹æ˜¯å¦å·²ç§»åˆ° GPUï¼ˆ`model.to(device)`ï¼‰ï¼Ÿ
- [ ] æå¤±å‡½æ•¸æ˜¯å¦å·²ç§»åˆ° GPUï¼ˆå¦‚éœ€è¦ï¼‰ï¼Ÿ
- [ ] æ‰€æœ‰è¼¸å…¥å¼µé‡æ˜¯å¦åœ¨åŒä¸€è¨­å‚™ä¸Šï¼Ÿ

### æ¨ç†å’Œè©•ä¼°
- [ ] æ˜¯å¦ä½¿ç”¨ `torch.no_grad()` åŒ…è£¹æ¨ç†ä»£ç¢¼ï¼Ÿ
- [ ] è©•ä¼°æ•¸æ“šæ˜¯å¦æ­£ç¢ºç§»åˆ° GPUï¼Ÿ
- [ ] å¦‚æœéœ€è¦åœ¨ CPU ä¸Šè™•ç†çµæœï¼Œæ˜¯å¦ä½¿ç”¨ `.cpu()`ï¼Ÿ

---

## ğŸ› ï¸ å¸¸è¦‹éŒ¯èª¤æ¨¡å¼å’Œä¿®å¾©

### éŒ¯èª¤æ¨¡å¼ 1: éƒ¨åˆ†å¼µé‡åœ¨ GPUï¼Œéƒ¨åˆ†åœ¨ CPU

```python
# âŒ éŒ¯èª¤
x = x.to(device)
y = torch.zeros(10)  # åœ¨ CPU ä¸Š
z = x + y  # RuntimeError!

# âœ… ä¿®å¾©
x = x.to(device)
y = torch.zeros(10, device=device)  # åœ¨ GPU ä¸Š
z = x + y  # OK
```

### éŒ¯èª¤æ¨¡å¼ 2: å¾ªç’°ä¸­é‡è¤‡è½‰æ›

```python
# âŒ éŒ¯èª¤ï¼ˆæ•ˆç‡ä½ï¼‰
for batch in dataloader:
    x = batch['x'].to(device)
    y = batch['y'].to(device)
    z = batch['z'].to(device)

# âœ… ä¿®å¾©
for batch in dataloader:
    batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}
```

### éŒ¯èª¤æ¨¡å¼ 3: å¿˜è¨˜å°‡æ¨™ç±¤ç§»åˆ° GPU

```python
# âŒ éŒ¯èª¤
for images, labels in dataloader:
    images = images.to(device)
    outputs = model(images)
    loss = criterion(outputs, labels)  # labels é‚„åœ¨ CPUï¼

# âœ… ä¿®å¾©
for images, labels in dataloader:
    images = images.to(device, non_blocking=True)
    labels = labels.to(device, non_blocking=True)
    outputs = model(images)
    loss = criterion(outputs, labels)
```

---

## ğŸ“Š ä¿®å¾©ç¸½çµ

| æ–‡ä»¶ | è¡Œæ•¸ | å•é¡Œ | ä¿®å¾© |
|-----|------|------|------|
| train.py | 180-181 | æ•¸æ“šæœªç§»åˆ° GPU | æ·»åŠ  `.to(device)` |
| train.py | 205, 214, 217 | é‡è¤‡è½‰æ› | ç§»é™¤é‡è¤‡èª¿ç”¨ |
| train.py | 246-247 | é‡è¤‡è½‰æ› | ç§»é™¤é‡è¤‡èª¿ç”¨ |
| train.py | 291 | label_test åœ¨ CPU | æ·»åŠ  `device=device` |
| eval.py | 122 | create_labels åœ¨ CPU | æ·»åŠ  `device=device` |

---

## ğŸ”¬ æ¸¬è©¦å»ºè­°

åœ¨ä¿®æ”¹å¾Œï¼Œå»ºè­°é‹è¡Œä»¥ä¸‹æ¸¬è©¦ï¼š

```bash
# 1. å¿«é€Ÿæ¸¬è©¦ï¼ˆé‹è¡Œå¹¾å€‹è¿­ä»£ï¼‰
python train.py --config configs/default.yaml

# 2. æª¢æŸ¥è¨­å‚™ä½¿ç”¨
# åœ¨ä»£ç¢¼ä¸­æ·»åŠ ï¼š
if it == 0:
    print(f"x_real device: {x_real.device}")
    print(f"label device: {label.device}")
    print(f"Generator device: {next(generator.parameters()).device}")
    print(f"Discriminator device: {next(discriminator.parameters()).device}")

# 3. è¨˜æ†¶é«”ç›£æ§
watch -n 1 nvidia-smi
```

---

## ğŸ“š åƒè€ƒè³‡æ–™

- [PyTorch è¨­å‚™ç®¡ç†æ–‡æª”](https://pytorch.org/docs/stable/notes/cuda.html)
- [PyTorch æ€§èƒ½å„ªåŒ–æŒ‡å—](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)
- [CUDA æœ€ä½³å¯¦è¸](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)

---

**æœ€å¾Œæ›´æ–°**: 2025-10-21
**ç¶­è­·è€…**: Claude Code Review Assistant

---

## âš¡ å¿«é€Ÿåƒè€ƒ

### å¸¸ç”¨è¨­å‚™æ“ä½œ

```python
# æª¢æŸ¥è¨­å‚™
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ç§»å‹•å¼µé‡
tensor = tensor.to(device)
tensor = tensor.cuda()  # ç­‰åŒæ–¼ .to('cuda')
tensor = tensor.cpu()   # ç§»å› CPU

# å‰µå»ºæ™‚æŒ‡å®šè¨­å‚™
tensor = torch.zeros(10, device=device)

# æª¢æŸ¥å¼µé‡è¨­å‚™
print(tensor.device)
assert tensor.is_cuda

# ç•°æ­¥å‚³è¼¸
tensor = tensor.to(device, non_blocking=True)
```

### èª¿è©¦å‘½ä»¤

```python
# æ‰“å°æ‰€æœ‰å¼µé‡çš„è¨­å‚™
for name, param in model.named_parameters():
    print(f"{name}: {param.device}")

# æª¢æŸ¥è¨ˆç®—åœ–ä¸­çš„è¨­å‚™
torch.autograd.set_detect_anomaly(True)
```
